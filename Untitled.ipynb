{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yWamPaEwHy_"
      },
      "outputs": [],
      "source": [
        "# What is a parameter?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters are internal variables in a machine learning model that are learned from the training data. For example, in linear regression, the coefficients (weights) and intercept are parameters.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "y = np.array([2, 3, 4, 5])\n",
        "\n",
        "# Model initialization\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Getting parameters (coefficients and intercept)\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "id": "QVBPrI3fwPdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is correlation?"
      ],
      "metadata": {
        "id": "MQO9lmdGwckn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation is a statistical measure that describes the extent to which two variables move in relation to each other. It is usually expressed as a number between -1 and 1. A correlation of 1 means they move in the same direction perfectly, -1 means they move in opposite directions perfectly, and 0 means no relationship.  \n",
        "\n",
        "Negative correlation means that as one variable increases, the other decreases. For example, as the number of hours worked increases, leisure time decreases.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {'x': [1, 2, 3, 4, 5], 'y': [10, 9, 6, 5, 2]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute correlation\n",
        "correlation = df.corr()\n",
        "print(correlation)\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data with negative correlation\n",
        "data = {'x': [1, 2, 3, 4, 5], 'y': [10, 9, 7, 5, 2]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Plot negative correlation\n",
        "sns.scatterplot(x='x', y='y', data=df)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EjzE1naPwg6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Machine Learning. What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "o93JZOEbwm-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning is a subset of artificial intelligence that enables a system to automatically learn from data and improve performance over time without being explicitly programmed.  \n",
        "\n",
        "Data: The raw material for machine learning models.\n",
        "\n",
        "Model: A mathematical representation of a real-world process.\n",
        "\n",
        "Training: The process of learning the model parameters from data.\n",
        "\n",
        "Evaluation: Assessing the model's performance.\n",
        "\n",
        "Prediction: Using the model to make decisions or predictions.\n"
      ],
      "metadata": {
        "id": "h2OQCn0Iw9eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How does loss value help in determining whether the model is good or not?"
      ],
      "metadata": {
        "id": "xbNPt0r2xEVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss value measures how far the predictions of the model are from the actual values. A lower loss indicates better model performance.\n",
        "\n",
        " (Loss value in Regression):\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Predictions and actual values\n",
        "y_true = [2, 3, 4, 5]\n",
        "y_pred = [2.1, 2.9, 4.2, 4.8]\n",
        "\n",
        "# Mean Squared Error (MSE) as the loss value\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "FYksghPxxK_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "EtEnqyrsxpL9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuous Variables: Variables that can take an infinite number of values, e.g., height, weight.\n",
        "Categorical Variables: Variables that represent categories, e.g., gender, country."
      ],
      "metadata": {
        "id": "kOIsKO6GxwTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we handle categorical variables in Machine Learning? What are the common t echniques?"
      ],
      "metadata": {
        "id": "lWuT9PXIxvZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical variables are converted into numerical form using techniques like one-hot encoding or label encoding.\n",
        "\n",
        " (One-Hot Encoding in Python using Scikit-learn):\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample categorical data\n",
        "categories = np.array([['Male'], ['Female'], ['Female'], ['Male']])\n",
        "\n",
        "# One-Hot Encoding\n",
        "encoder = OneHotEncoder()\n",
        "encoded = encoder.fit_transform(categories).toarray()\n",
        "print(encoded)"
      ],
      "metadata": {
        "id": "95aJoXygx9vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What do you mean by training and testing a dataset?"
      ],
      "metadata": {
        "id": "xml6nLKTyGxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "raining a dataset means using it to teach the model by adjusting its parameters. Testing a dataset means evaluating the model's performance on unseen data.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (X = features, y = target)\n",
        "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])  # Feature values\n",
        "y = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10, 11])  # Target values\n",
        "\n",
        "# Step 1: Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Initialize the model (Linear Regression)\n",
        "model = LinearRegression()\n",
        "\n",
        "# Step 3: Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model's performance (using Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"Test Set Predictions:\", y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "fLcRZKj0yidB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "zP7SoJ0jy-LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn.preprocessing is a module in Scikit-learn used for data preprocessing tasks like scaling, normalization, encoding, and more."
      ],
      "metadata": {
        "id": "xXJUHz1_zDtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a Test set?"
      ],
      "metadata": {
        "id": "KuumTSutzHmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " A test set is a portion of the dataset that is used to evaluate the performance of the machine learning model after it has been trained.\n"
      ],
      "metadata": {
        "id": "VZcmDTsMNCwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we split data for model fitting (training and testing) in Python?\n",
        "#  How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "bkZN5iDDNGcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "y = np.array([2, 3, 4, 5])\n",
        "\n",
        "# Split data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training Set:\", X_train, y_train)\n",
        "print(\"Test Set:\", X_test, y_test)\n",
        "\n",
        "Define the problem.\n",
        "Collect and preprocess data.\n",
        "Perform Exploratory Data Analysis (EDA).\n",
        "Split the data into training and testing sets.\n",
        "Choose and train a model.\n",
        "Evaluate the model.\n",
        "Optimize the model.\n"
      ],
      "metadata": {
        "id": "qribrM-yNN6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why do we have to perform EDA before fitting a model to the data?"
      ],
      "metadata": {
        "id": "StdgYk1tNZ4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA helps to understand the data distribution, identify patterns, and detect any anomalies or missing values before building a machine learning model."
      ],
      "metadata": {
        "id": "JFstrCxCNfFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is correlation?"
      ],
      "metadata": {
        "id": "oGOvQR6qNp0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation measures the relationship between two variables and how they move in relation to each other. It ranges from -1 to 1, where 1 indicates perfect positive correlation, -1 indicates perfect negative correlation, and 0 means no correlation.  \n",
        "\n"
      ],
      "metadata": {
        "id": "RdSKDWU0NkR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What does negative correlation mean?"
      ],
      "metadata": {
        "id": "zzwFItEEN5Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative correlation means that as one variable increases, the other variable tends to decrease, and vice versa. For example, if temperature decreases, heating bills increase."
      ],
      "metadata": {
        "id": "Z9Y6jvLrN9yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "JO_DBn7hODCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {'x': [1, 2, 3, 4, 5], 'y': [10, 9, 6, 5, 2]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute correlation\n",
        "correlation = df.corr()\n",
        "print(correlation)\n"
      ],
      "metadata": {
        "id": "kBl_AHupOJM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is causation? Explain difference between correlation and causation with an example.?"
      ],
      "metadata": {
        "id": "IR2d7aDGOPmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation: Measures the relationship between two variables.\n",
        "\n",
        "Causation: Indicates that one event is the result of the occurrence of another event.\n",
        "\n",
        "Example: Correlation may show that ice cream sales and drowning incidents increase in summer, but ice cream doesn't cause drowning; the hot weather does."
      ],
      "metadata": {
        "id": "NCxWwjiBOaSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is an Optimizer? What are different types of optimizers? Explain each with an example."
      ],
      "metadata": {
        "id": "A9idSse2Oryo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An optimizer in machine learning adjusts the model's parameters (like weights) to minimize the loss function. Examples of optimizers include:\n",
        "\n",
        "SGD (Stochastic Gradient Descent)\n",
        "Adam (Adaptive Moment Estimation)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Sample model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model with Adam optimizer\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "jypXOUlYOxOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "XFirEeC0O6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn.linear_model is a Scikit-learn module for implementing linear models such as Linear Regression, Logistic Regression, Ridge, Lasso, etc."
      ],
      "metadata": {
        "id": "RFi2VNgSPGAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What does model.fit() do? What arguments must be given?"
      ],
      "metadata": {
        "id": "qqMyJTM_PLVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " model.fit() trains the machine learning model by adjusting its parameters using the provided data.\n",
        "\n",
        " model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "2Ka4EzqePQG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What does model.predict() do? What arguments must be given?"
      ],
      "metadata": {
        "id": "CYwmYH9TPX8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.fit() is used to train the machine learning model. It adjusts the model's parameters based on the input data (features) and target labels.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "X (Features/Independent variables)\n",
        "y (Target/Dependent variable)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train = [[1], [2], [3], [4]]\n",
        "y_train = [2, 4, 6, 8]\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # Train the model\n"
      ],
      "metadata": {
        "id": "GwoCT_gnRr3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "q6yG2q1sSXZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuous Variables: Variables that can take an infinite range of values (e.g., height, weight).\n",
        "Categorical Variables: Variables that represent categories or groups (e.g., gender, country)."
      ],
      "metadata": {
        "id": "aaRYB-W5Smi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is feature scaling? How does it help in Machine Learning?"
      ],
      "metadata": {
        "id": "qL7idHTLTCF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling is a technique to normalize or standardize the range of independent variables/features. It helps by ensuring that features with larger scales do not dominate others and allows gradient-based algorithms to converge faster.\n"
      ],
      "metadata": {
        "id": "x5UCCvfxTGNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we perform scaling in Python?"
      ],
      "metadata": {
        "id": "OnzlsScoTLhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample data\n",
        "X = [[1, 2], [2, 3], [3, 4], [4, 5]]\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "id": "s7619OGUVZf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "BaTqN230Vcov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn.preprocessing is a module in Scikit-learn used for transforming and normalizing data, including scaling, encoding, and imputing missing values"
      ],
      "metadata": {
        "id": "zYmx_bDhVitL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we split data for model fitting (training and testing) in Python?"
      ],
      "metadata": {
        "id": "LPDvgByOVnCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data\n",
        "X = [[1], [2], [3], [4], [5], [6]]\n",
        "y = [2, 4, 6, 8, 10, 12]\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data:\", X_train)\n",
        "print(\"Test data:\", X_test)\n"
      ],
      "metadata": {
        "id": "IXINYy6-VrcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain data encoding?"
      ],
      "metadata": {
        "id": "soGFRnAcVvUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data encoding converts categorical variables into numerical values so they can be used in machine learning models. Common techniques include:\n",
        "\n",
        "Label Encoding: Converts each category into a numerical label.\n",
        "One-Hot Encoding: Creates binary columns for each category.\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Sample categorical data\n",
        "categories = np.array([['Male'], ['Female'], ['Female'], ['Male']])\n",
        "\n",
        "# One-Hot Encoding\n",
        "encoder = OneHotEncoder()\n",
        "encoded = encoder.fit_transform(categories).toarray()\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "id": "tsVApM4lV1Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2xdA2OHV9E9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}